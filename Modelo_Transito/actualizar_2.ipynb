{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import matplotlib\n",
    "matplotlib.use ('template')\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import os\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estaciones = [91,94,93,99,140]\n",
    "tipos = ['Ni','Ni','Ni','Ni','Ni']\n",
    "cuencas = ['Metro_Sabaneta','Aguacatala','Puente_La33','Aula_Ambiental','Puente_Fundadores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros estacion a actualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 140\n",
    "ee = np.where(np.array(estaciones) == n)[0]\n",
    "tip = np.array(tipos)[ee]\n",
    "umb_niv = 270\n",
    "path='/media/nicolas/Home/Jupyter/Esneider/modelo_crecidas/Buscador_eventos/'+np.array(cuencas)[ee][0]+'/'\n",
    "\n",
    "FI='2017-09-10'\n",
    "FF='2018-01-17'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find maximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Consulta en base de datos\n",
    "\n",
    "host      ='192.168.1.74'\n",
    "user      ='usrCalidad'\n",
    "passw     ='aF05wnXC;'\n",
    "bd_nombre ='siata'\n",
    "\n",
    "Estaciones=\"SELECT Codigo,Nombreestacion, offsetN, red  FROM estaciones WHERE codigo=(\"+str(n)+\")\"\n",
    "db = MySQLdb.connect(host, user,passw,bd_nombre)\n",
    "db_cursor = db.cursor()\n",
    "db_cursor.execute(Estaciones)\n",
    "Cod = db_cursor.fetchall()\n",
    "date_ini=datetime.datetime(int(FI[0:4]),int(FI[5:7]),int(FI[8:10]))\n",
    "date_fin=datetime.datetime(int(FF[0:4]),int(FF[5:7]),int(FF[8:10]))\n",
    "sql_datos =\"SELECT fecha, DATE_FORMAT(fecha,'%Y-%m-%d'), hora, DATE_FORMAT(hora, '%H:%i:%s'), Cliente, (\" +str(Cod[0][2])+\"-\"+tip[0]+\"), calidad FROM datos WHERE cliente = \"+str(n)+\" and (((fecha>'\"+str(date_ini.year)+\"-\"+str(date_ini.month)+\"-\"+str(date_ini.day)+\"') or (fecha='\"+str(date_ini.year)+\"-\"+str(date_ini.month)+\"-\"+str(date_ini.day)+\"' and hora>='\"+str(date_ini.hour)+\":\"+str(date_ini.minute)+\":00')) and ((fecha<'\"+str(date_fin.year)+\"-\"+str(date_fin.month)+\"-\"+str(date_fin.day)+\"') or (fecha='\"+str(date_fin.year)+\"-\"+str(date_fin.month)+\"-\"+str(date_fin.day)+\"' and hora<='\"+str(date_fin.hour)+\":\"+str(date_fin.minute)+\":00')))\"\n",
    "\n",
    "db = MySQLdb.connect(host, user,passw,bd_nombre)\n",
    "db_cursor = db.cursor()\n",
    "db_cursor.execute(sql_datos)\n",
    "data = db_cursor.fetchall()\n",
    "\n",
    "db_cursor.execute(Estaciones)\n",
    "Nombre = db_cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:44: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(min_periods=8,window=20,center=True).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Graficar las hidrografas de los eventos nuevos y seleccionar los buenos\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "F=[]\n",
    "H=[]\n",
    "ID=[]\n",
    "N=[]\n",
    "Calidad=[]\n",
    "FH=[]\n",
    "\n",
    "for dato in data:\n",
    "    if dato[6] != 151:\n",
    "        F.append(dato[1])\n",
    "        H.append(dato[3])\n",
    "        ID.append(dato[4])\n",
    "        N.append(dato[5])\n",
    "        Calidad.append(dato[6])  \n",
    "    \n",
    "for i in range(len(F)):\n",
    "    fh=F[i]+\" \"+H[i]\n",
    "    FH.append(fh)\n",
    "    \n",
    "#Hasta este punto se han extraido datos de nivel y tal cual estan en la base de datos\n",
    "#vector fechas para comparar fechas de las estaciones de Nivel y Precipitacion\n",
    "    \n",
    "EjeX=[]\n",
    "EjeY=[]\n",
    "formato = '%Y-%m-%d %H:%M:%S'\n",
    "C=0\n",
    "\n",
    "ID2=[]\n",
    "Calidad2=[]\n",
    "FH1 = []\n",
    "        \n",
    "vv = np.where(np.array(Calidad) != 151)[0]\n",
    "EjeY = np.array(N)[vv]\n",
    "FH1 = np.array(FH)[vv]\n",
    "    \n",
    "for i in FH1:\n",
    "    EjeX.append(datetime.datetime.strptime (i[:-3], '%Y-%m-%d %H:%M'))        \n",
    "\n",
    "D = pd.Series(EjeY, EjeX)\n",
    "\n",
    "#Suavizado de serie\n",
    "j=0\n",
    "while j<2:\n",
    "    d_mva = pd.rolling_mean(D,20,min_periods=8,center=True)\n",
    "    D1=d_mva\n",
    "    j+=1\n",
    "\n",
    "#Hallar maximos\n",
    "Ejey = D1.values\n",
    "EjeX = D1.index\n",
    "\n",
    "ite = 3\n",
    "umbral = umb_niv\n",
    "busq = 30\n",
    "\n",
    "#Hallar maximos locales\n",
    "\n",
    "def maximos(Ejy,EjX):\n",
    "    \n",
    "    grad = []\n",
    "    maxi = []\n",
    "    picos = []\n",
    "    datesM = []\n",
    "    \n",
    "    for j in range(len(Ejy)-1):\n",
    "        if Ejy[j+1] == Ejy[j]:\n",
    "            grad.append(1)\n",
    "        \n",
    "        if Ejy[j+1] != Ejy[j]:\n",
    "            grad.append((Ejy[j+1]-Ejy[j])/abs(Ejy[j+1]-Ejy[j]))     \n",
    "    \n",
    "    for i in range(len(grad)-1):\n",
    "        maxi.append(grad[i+1]-grad[i])\n",
    "         \n",
    "    pp = (np.where(np.array(maxi) == -2))[0]\n",
    "    pp = pp+np.ones(len(pp))\n",
    "    \n",
    "    for x in range(len(pp)):\n",
    "        picos.append(Ejy[int(pp[x])])\n",
    "        datesM.append(EjX[int(pp[x])])\n",
    "\n",
    "    return picos,datesM\n",
    "    \n",
    "for i in range(ite):\n",
    "    if i == 0:\n",
    "        aux = maximos(Ejey,EjeX)\n",
    "    if i > 0:\n",
    "        aux = maximos(aux[0],aux[1])\n",
    "        \n",
    "pi1 = []\n",
    "da1 = []\n",
    "    \n",
    "for y in aux[1]:\n",
    "    fa = np.where(EjeX == y)[0]\n",
    "    fa = fa[len(fa)-1]\n",
    "    if fa > busq:\n",
    "        ma = np.where(EjeY[fa-busq:fa] == np.max(EjeY[fa-busq:fa]))[0]\n",
    "        pi1.append(EjeY[fa-(busq-ma[len(ma)-1])])\n",
    "        da1.append(EjeX[fa-(busq-ma[len(ma)-1])])     \n",
    "\n",
    "dM = np.array(da1)\n",
    "NM = np.array(pi1) \n",
    "dM = dM[NM >= umbral]\n",
    "NM = NM[NM >= umbral]\n",
    "M = pd.Series(NM, dM)\n",
    "\n",
    "fig1=pl.figure(1,edgecolor='w',facecolor='w',figsize=(15,15))\n",
    "plt.close('all')\n",
    "plt.clf ()\n",
    "plt.cla ()\n",
    "D.plot()\n",
    "D1.plot()\n",
    "M.plot()\n",
    "plt.savefig(path+'maximos.png')\n",
    "\n",
    "np.savetxt(path+'fechas_1.txt',np.array(dM),fmt=\"%s\")\n",
    "np.savetxt(path+'niveles_1.txt',NM)\n",
    "\n",
    "print '--------------------------------------------------------------------------'\n",
    "print 'Graficar las hidrografas de los eventos nuevos y seleccionar los buenos'\n",
    "print '--------------------------------------------------------------------------'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fechas=np.loadtxt(path+'fechas_1.txt',dtype=str)\n",
    "\n",
    "# open database connection\n",
    "host      ='192.168.1.74'\n",
    "user      ='usrCalidad'\n",
    "passw     ='aF05wnXC;'\n",
    "bd_nombre ='siata'\n",
    "\n",
    "Estaciones=\"SELECT Codigo,Nombreestacion, offsetN, red  FROM estaciones WHERE codigo=(\"+str(n)+\")\"\n",
    "db = MySQLdb.connect(host, user,passw,bd_nombre)\n",
    "db_cursor = db.cursor()\n",
    "db_cursor.execute(Estaciones)\n",
    "Cod = db_cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-09-10' '01:45:00']\n",
      "['2017-09-12' '23:25:00']\n",
      "['2017-09-13' '18:33:00']\n",
      "['2017-09-14' '19:40:00']\n",
      "['2017-09-15' '05:09:00']\n",
      "['2017-09-16' '04:01:00']\n",
      "['2017-09-17' '02:39:00']\n",
      "['2017-09-19' '17:22:00']\n",
      "['2017-09-20' '09:29:00']\n",
      "['2017-09-21' '15:35:00']\n",
      "['2017-09-22' '00:25:00']\n",
      "['2017-09-22' '16:17:00']\n",
      "['2017-09-22' '20:52:00']\n",
      "['2017-09-23' '18:15:00']\n",
      "['2017-09-26' '15:04:00']\n",
      "['2017-09-27' '08:48:00']\n",
      "['2017-09-27' '15:58:00']\n",
      "['2017-09-30' '05:41:00']\n",
      "['2017-09-30' '18:56:00']\n",
      "['2017-10-01' '15:42:00']\n",
      "['2017-10-02' '17:16:00']\n",
      "['2017-10-03' '13:10:00']\n",
      "['2017-10-03' '16:37:00']\n",
      "['2017-10-08' '16:15:00']\n",
      "['2017-10-09' '15:43:00']\n",
      "['2017-10-11' '06:15:00']\n",
      "['2017-10-14' '23:40:00']\n",
      "['2017-10-20' '22:52:00']\n",
      "['2017-10-21' '17:55:00']\n",
      "['2017-10-22' '15:51:00']\n",
      "['2017-10-25' '16:04:00']\n",
      "['2017-10-25' '19:44:00']\n",
      "['2017-10-26' '12:32:00']\n",
      "['2017-10-26' '15:47:00']\n",
      "['2017-10-27' '17:38:00']\n",
      "['2017-10-28' '13:17:00']\n",
      "['2017-11-01' '01:43:00']\n",
      "['2017-11-03' '02:23:00']\n",
      "['2017-11-03' '18:11:00']\n",
      "['2017-11-04' '01:27:00']\n",
      "['2017-11-08' '16:25:00']\n",
      "['2017-11-09' '15:37:00']\n",
      "['2017-11-10' '18:03:00']\n",
      "['2017-11-11' '01:01:00']\n",
      "['2017-11-13' '15:38:00']\n",
      "['2017-11-14' '16:21:00']\n",
      "['2017-11-15' '00:54:00']\n",
      "['2017-11-15' '06:47:00']\n",
      "['2017-11-16' '01:01:00']\n",
      "['2017-11-16' '06:45:00']\n",
      "['2017-11-17' '20:34:00']\n",
      "['2017-11-18' '01:02:00']\n",
      "['2017-11-18' '06:45:00']\n",
      "['2017-11-18' '22:20:00']\n",
      "['2017-11-19' '01:36:00']\n",
      "['2017-11-19' '11:06:00']\n",
      "['2017-11-19' '11:18:00']\n",
      "['2017-11-19' '13:50:00']\n",
      "['2017-11-19' '20:01:00']\n",
      "['2017-11-20' '17:25:00']\n",
      "['2017-11-20' '19:33:00']\n",
      "['2017-11-21' '17:24:00']\n",
      "['2017-11-22' '16:59:00']\n",
      "['2017-11-24' '04:41:00']\n",
      "['2017-11-24' '17:27:00']\n",
      "['2017-11-27' '18:18:00']\n",
      "['2017-11-29' '16:48:00']\n",
      "['2017-12-01' '00:47:00']\n",
      "['2017-12-01' '16:40:00']\n",
      "['2017-12-02' '16:17:00']\n",
      "['2017-12-05' '02:53:00']\n",
      "['2017-12-08' '17:47:00']\n",
      "['2017-12-09' '02:03:00']\n",
      "['2017-12-09' '16:57:00']\n",
      "['2017-12-10' '17:37:00']\n",
      "['2017-12-11' '00:42:00']\n",
      "['2017-12-12' '21:33:00']\n",
      "['2017-12-28' '06:00:00']\n",
      "['2017-12-30' '03:58:00']\n",
      "['2017-12-31' '07:40:00']\n",
      "['2018-01-01' '20:26:00']\n",
      "['2018-01-02' '21:49:00']\n",
      "['2018-01-03' '16:55:00']\n",
      "['2018-01-04' '04:48:00']\n",
      "['2018-01-04' '22:46:00']\n",
      "['2018-01-05' '16:50:00']\n",
      "['2018-01-08' '20:45:00']\n",
      "['2018-01-09' '06:09:00']\n",
      "['2018-01-09' '10:50:00']\n",
      "['2018-01-09' '21:18:00']\n",
      "['2018-01-10' '19:09:00']\n",
      "-----------------------------------------\n",
      "Eliminar hidrográfas para filtrar\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Itera por evento\n",
    "\n",
    "for w in np.arange(0,len(fechas),1):\n",
    "    i=fechas[w]\n",
    "    print i\n",
    "    dt_fecha = datetime.datetime(int(i[0][0:4]),int(i[0][5:7]),int(i[0][8:10]),int(i[1][0:2]),int(i[1][3:5]))\n",
    "\n",
    "    #extraer de la base de datos fecha, hora y nivel el vector fecha debe quedar en el formato '%Y-%m-%d %H:%M:%S' datetime\n",
    "    date_ini=dt_fecha-datetime.timedelta(minutes=60)\n",
    "    date_fin=dt_fecha+datetime.timedelta(minutes=180)\n",
    "    datos_n = \"SELECT fecha, DATE_FORMAT(fecha,'%Y-%m-%d'), hora, DATE_FORMAT(hora, '%H:%i:%s'), (\" +str(Cod[0][2])+\"-\"+tip[0]+\"), calidad FROM datos WHERE cliente = \"+str(n)+\" and (((fecha>'\"+str(date_ini.year)+\"-\"+str(date_ini.month)+\"-\"+str(date_ini.day)+\"') or (fecha='\"+str(date_ini.year)+\"-\"+str(date_ini.month)+\"-\"+str(date_ini.day)+\"' and hora>='\"+str(date_ini.hour)+\":\"+str(date_ini.minute)+\":00')) and ((fecha<'\"+str(date_fin.year)+\"-\"+str(date_fin.month)+\"-\"+str(date_fin.day)+\"') or (fecha='\"+str(date_fin.year)+\"-\"+str(date_fin.month)+\"-\"+str(date_fin.day)+\"' and hora<='\"+str(date_fin.hour)+\":\"+str(date_fin.minute)+\":00')))\"\n",
    "    db = MySQLdb.connect(host, user,passw,bd_nombre)\n",
    "    db_cursor = db.cursor()\n",
    "    db_cursor.execute(datos_n)\n",
    "    data = db_cursor.fetchall()\n",
    "\n",
    "    FN=[]\n",
    "    N=[]\n",
    "    calidad=[]\n",
    "\n",
    "    for k in range(len(data)):\n",
    "        try:\n",
    "            dato = data[k]\n",
    "            dt = datetime.datetime(int(dato[1][0:4]),int(dato[1][5:7]),int(dato[1][8:10]),int(dato[3][0:2]),int(dato[3][3:5]))\n",
    "            FN.append(dt)\n",
    "            N.append(dato[4])\n",
    "            calidad.append(dato[5])\n",
    "            if dt == dt_fecha:\n",
    "                pp = k\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    cc = np.where(np.array(calidad) != 151)[0]\n",
    "    FN = np.array(FN)[cc]\n",
    "    N = np.array(N)[cc]\n",
    "\n",
    "    N=pd.Series(map(float,N),FN) # construir serie de nivel en formato pandas\n",
    "\n",
    "    plt.close('all')\n",
    "    fig=plt.figure(edgecolor='w',facecolor='w',figsize=(12,9))\n",
    "    plt.plot(list(N.index),list(N.values), lw=2)\n",
    "    plt.grid(linestyle='--')\n",
    "    plt.xlabel(\"Hora\")\n",
    "    plt.ylabel(\"N (cm)\")\n",
    "    plt.title('Evento '+str(i[0])+' ('+str(w+1)+')')\n",
    "    matplotlib.rcParams.update({'font.size': 10})\n",
    "\n",
    "    try:\n",
    "        plt.savefig(path+'Hidrografas/'+str(i[0])+'*'+str(i[1])+'.png')\n",
    "    except:pass\n",
    "\n",
    "print '-----------------------------------------'\n",
    "print 'Eliminar hidrográfas para filtrar'\n",
    "print '-----------------------------------------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar las hidrografas que no se tendran en cuenta en la actualizacion y continuar con el proceso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unir corridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "Revisar que los archivos niveles.txt y fechas.txt esten actualizados\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fechas_toda=np.loadtxt(path+'fechas_1.txt',dtype=str)\n",
    "nivel_todo=np.loadtxt(path+'niveles_1.txt')\n",
    "a=os.listdir(path+'/Hidrografas/')\n",
    "a.sort()\n",
    "a = a[1::] \n",
    "\n",
    "fecha_t=[] ; hora_t=[]\n",
    "for kk in fechas_toda:\n",
    "    fecha_t.append(kk[0])\n",
    "    hora_t.append(kk[1])\n",
    "\n",
    "fecha=[] ; hora=[] ; nivel=[] ; fecha_str = []\n",
    "for k in a:\n",
    "    fecha.append(k.split('*')[0])\n",
    "    hora.append(k.split('*')[1].split('.')[0])\n",
    "    dd=np.where(np.array(fecha_t) == k.split('*')[0])[0]\n",
    "    ee=np.where(np.array(hora_t) == k.split('*')[1].split('.')[0])[0]\n",
    "    ff=list(set(dd).intersection(ee))\n",
    "    nivel.append(float(nivel_todo[ff]))\n",
    "    fecha_str.append(k.split('*')[0]+' '+k.split('*')[1].split('.')[0])\n",
    "\n",
    "# Guardar nuevo \n",
    "np.savetxt(path+'fechas_1.txt',fecha_str,fmt=\"%s\")\n",
    "np.savetxt(path+'niveles_1.txt',nivel,fmt=\"%s\")\n",
    "\n",
    "#Actualizar archivos a unir\n",
    "\n",
    "fechas_C1=np.loadtxt(path+'fechas.txt',dtype=str)\n",
    "niveles_C1=np.loadtxt(path+'niveles.txt',dtype=str)\n",
    "\n",
    "fechas=[]\n",
    "niveles=[]\n",
    "\n",
    "for i in range(len(fechas_C1)):\n",
    "\n",
    "    niveles.append(niveles_C1[i])\n",
    "    fechas.append(fechas_C1[i][0]+' '+fechas_C1[i][1])\n",
    "\n",
    "for j in range(len(fecha)):\n",
    "\n",
    "    niveles.append(nivel[j])\n",
    "    fechas.append(fecha[j]+' '+hora[j])\n",
    "\n",
    "os.system(\"sudo cp \"+path+\"/Hidrografas/*.png \"+path+\"/Hidrografas_todas/\")\n",
    "\n",
    "np.savetxt(path+'/niveles.txt',niveles,fmt=\"%s\")\n",
    "np.savetxt(path+'/fechas.txt',fechas,fmt=\"%s\")\n",
    "\n",
    "print '--------------------------------------------------------------------------------------'\n",
    "print 'Revisar que los archivos niveles.txt y fechas.txt esten actualizados'\n",
    "print '--------------------------------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/nicolas/Home/Jupyter/Esneider/modelo_crecidas/Buscador_eventos/Puente_Fundadores/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elaborar graficas resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fechas=np.loadtxt(path+'fechas.txt',dtype=str)\n",
    "nivp=np.genfromtxt(path+'niveles.txt',dtype=float)\n",
    "dates=[]\n",
    "mes=[]\n",
    "\n",
    "for i in fechas:\n",
    "    dates.append(datetime.datetime(int(i[0][0:4]),int(i[0][5:7]),int(i[0][8:10]),int(i[1][0:2]),int(i[1][3:5])))\n",
    "    mes.append(int(i[0][5:7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Histograma de niveles\n",
    "\n",
    "clases = 6\n",
    "binx = (np.max(nivp)-np.min(nivp))/clases\n",
    "ejex = np.arange(np.min(nivp), np.max(nivp)+binx, binx)\n",
    "hist = ((np.histogram(nivp,bins=ejex))[0])\n",
    "plt.close ('all')\n",
    "fig=plt.figure(1,edgecolor='w',facecolor='w',figsize=(15,15))\n",
    "ax1=fig.add_subplot(1,1,1)   \n",
    "plt.bar(np.arange(np.min(nivp)+binx, np.max(nivp)+binx,binx)-binx/2,(hist/float(len(nivp)))*100,align='center',width=200)\n",
    "plt.xlim(70,150)\n",
    "ax1.set_xticks (np.arange(np.min(nivp)+binx, np.max(nivp)+binx,binx)-binx/2)\n",
    "ax1.set_xticklabels (map (lambda (x) : \"%.2f\" % (x), np.arange(np.min(nivp)+binx, np.max(nivp)+binx,binx)-binx/2), size=12)\n",
    "plt.grid()\n",
    "plt.title('Numero eventos - Total = '+str(len(nivp)),size=24)\n",
    "plt.xlabel('Nivel [cm]',size=24)\n",
    "plt.ylabel('Frecuencia [%]',size=24)\n",
    "plt.tick_params(axis='y', which='major', labelsize=22)\n",
    "plt.tick_params(axis='x', which='major', labelsize=22)\n",
    "plt.savefig(path+'hist_niveles.png')\n",
    "\n",
    "# Ciclo anual\n",
    "\n",
    "p10=np.zeros((12))\n",
    "p25=np.zeros((12))\n",
    "p50=np.zeros((12))\n",
    "p75=np.zeros((12))\n",
    "p90=np.zeros((12))\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    tem = []\n",
    "    for j in range(len(mes)):\n",
    "        if mes[j] == i+1:\n",
    "            tem.append(nivp[j])\n",
    "    try:\n",
    "        p10[i]=np.percentile(tem,10)\n",
    "        p25[i]=np.percentile(tem,25)\n",
    "        p50[i]=np.percentile(tem,50)\n",
    "        p75[i]=np.percentile(tem,75)\n",
    "        p90[i]=np.percentile(tem,90)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.close ('all')\n",
    "meses=['Ene','Feb','Mar','Abr','May','Jun','Jul','Ago','Sep','Oct','Nov','Dic']\n",
    "fig=plt.figure(1,edgecolor='w',facecolor='w',figsize=(15,15))\n",
    "ax1=fig.add_subplot(1,1,1) \n",
    "plt.plot(range(1,13,1),p10,label='Percentil 10',linewidth=2)\n",
    "plt.scatter(range(1,13,1),p10,s=50,color='b')\n",
    "plt.plot(range(1,13,1),p50,label='Percentil 50',linewidth=2)\n",
    "plt.scatter(range(1,13,1),p50,s=50,color='g')\n",
    "plt.plot(range(1,13,1),p90,label='Percentil 90',linewidth=2)\n",
    "plt.scatter(range(1,13,1),p90,s=50,color='r')\n",
    "plt.ylabel('Nivel [cm]',size=24)\n",
    "plt.tick_params(axis='y', which='major', labelsize=22)\n",
    "plt.tick_params(axis='x', which='major', labelsize=22)\n",
    "plt.grid()\n",
    "plt.xticks(range(1,13,1),meses,size=20)\n",
    "plt.xlim(1,12)\n",
    "plt.legend(loc=2)\n",
    "plt.savefig(path+'ciclo_anual.png')\n",
    "\n",
    "horas = []\n",
    "for h in fechas:\n",
    "    horas.append(float(h[1].split(':')[0]))\n",
    "\n",
    "fre = np.zeros((24))\n",
    "for i in horas:\n",
    "    fre[int(i)] = fre[int(i)] + 1\n",
    "\n",
    "plt.close ('all')\n",
    "fig=plt.figure(1,edgecolor='w',facecolor='w',figsize=(15,15))\n",
    "horas=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24']\n",
    "plt.bar(range(1,25,1),(np.array(fre)/sum(fre))*100,width=0.9)\n",
    "plt.grid()\n",
    "plt.xlim(1,25)\n",
    "plt.xticks(np.arange(1.5,25.5,1),horas,size=16)\n",
    "plt.tick_params(axis='y', which='major', labelsize=22)\n",
    "plt.ylabel('Frecuencia [%]',size=24)\n",
    "plt.xlabel('Horas',size=24)\n",
    "plt.savefig(path+'ciclo_horario.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copiar archivos a folder operacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('cp '+path+'niveles.txt /media/nicolas/Home/Jupyter/Esneider/modelo_crecidas/files/niveles'+str(n)+'.txt')\n",
    "os.system('cp '+path+'fechas.txt /media/nicolas/Home/Jupyter/Esneider/modelo_crecidas/files/fechas'+str(n)+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
